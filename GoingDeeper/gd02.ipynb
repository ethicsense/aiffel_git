{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gd02.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ow9oOeZmZb_g",
        "21vme0WpZjU4",
        "9B7VtYhWZl7g"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 머신러닝을 이용한 텍스트 분류기"
      ],
      "metadata": {
        "id": "dRfSZNjrookH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BnZqMnAofxF",
        "outputId": "e76d1de8-99c4-4d85-aad5-e0660ff9df58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n",
            "0.11.2\n",
            "1.21.5\n",
            "1.3.5\n",
            "1.0.2\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import reuters\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB #다항분포 나이브 베이즈 모델\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.naive_bayes import ComplementNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score #정확도 계산\n",
        "\n",
        "print(tf.__version__)\n",
        "print(sns.__version__)\n",
        "print(np.__version__)\n",
        "print(pd.__version__)\n",
        "print(sklearn.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 준비(머신 러닝)"
      ],
      "metadata": {
        "id": "ow9oOeZmZb_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb = MultinomialNB()\n",
        "cb = ComplementNB()\n",
        "lr = LogisticRegression(C=10000, penalty='l2')\n",
        "lsvc = LinearSVC(C=1000, penalty='l1', max_iter=500, dual=False)\n",
        "tree = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
        "forest = RandomForestClassifier(n_estimators=5, random_state=0)\n",
        "grbt = GradientBoostingClassifier(random_state=0) # verbose=3\n",
        "voting_classifier = VotingClassifier(estimators=[\n",
        "         ('lr', LogisticRegression(C=10000, penalty='l2')),\n",
        "        ('cb', ComplementNB()),\n",
        "        ('grbt', GradientBoostingClassifier(random_state=0))\n",
        "], voting='soft', n_jobs=-1)"
      ],
      "metadata": {
        "id": "mWNUM5WkzAAo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모든 단어 활용"
      ],
      "metadata": {
        "id": "PNuROJxjZgKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train1, y_train1), (x_test1, y_test1) = reuters.load_data(num_words=None, test_split=0.2)"
      ],
      "metadata": {
        "id": "W0wFHsRuowvm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('훈련용 뉴스의 최대 길이 :{}'.format(max(len(l) for l in x_train1)))\n",
        "print('훈련용 뉴스의 평균 길이 :{}'.format(sum(map(len, x_train1))/len(x_train1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90LUQ65_etmc",
        "outputId": "87dbe097-d7e2-40a0-f185-ba5fe88e1801"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련용 뉴스의 최대 길이 :2376\n",
            "훈련용 뉴스의 평균 길이 :145.5398574927633\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = max(y_train1) + 1\n",
        "print('클래스의 수 : {}'.format(num_classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmFkn0S8mKEe",
        "outputId": "2f88ef3a-6ba7-4b2e-c20b-6ef1f2213e03"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "클래스의 수 : 46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
        "index_to_word = { index+3 : word for word, index in word_index.items() }\n",
        "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
        "  index_to_word[index]=token"
      ],
      "metadata": {
        "id": "px-O_Y_nYE2l"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoded = []\n",
        "for i in range(len(x_train1)):\n",
        "    t = ' '.join([index_to_word[index] for index in x_train1[i]])\n",
        "    decoded.append(t)\n",
        "\n",
        "x_train1 = decoded\n",
        "print(len(x_train1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZ60AXTJYqC-",
        "outputId": "e5c5d532-118d-4613-f8f5-c0c8ed26ee54"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoded = []\n",
        "for i in range(len(x_test1)):\n",
        "    t = ' '.join([index_to_word[index] for index in x_test1[i]])\n",
        "    decoded.append(t)\n",
        "\n",
        "x_test1 = decoded\n",
        "print(len(x_test1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0qUr0NxYpDQ",
        "outputId": "0036040f-0c38-4a2c-fee9-2b2f861404f5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train1[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6vvRyjbfON3",
        "outputId": "68565d6b-4a08-4c05-b88a-f13d0e49940c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<sos> mcgrath rentcorp said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3',\n",
              " \"<sos> generale de banque sa lt genb br and lt heller overseas corp of chicago have each taken 50 pct stakes in factoring company sa belgo factors generale de banque said in a statement it gave no financial details of the transaction sa belgo factors' turnover in 1986 was 17 5 billion belgian francs reuter 3\",\n",
              " '<sos> shr 3 28 dlrs vs 22 cts shr diluted 2 99 dlrs vs 22 cts net 46 0 mln vs 3 328 000 avg shrs 14 0 mln vs 15 2 mln year shr 5 41 dlrs vs 1 56 dlrs shr diluted 4 94 dlrs vs 1 50 dlrs net 78 2 mln vs 25 9 mln avg shrs 14 5 mln vs 15 1 mln note earnings per share reflect the two for one split effective january 6 1987 per share amounts are calculated after preferred stock dividends loss continuing operations for the qtr 1986 includes gains of sale of investments in enron corp of 14 mln dlrs and associated companies of 4 189 000 less writedowns of investments in national intergroup inc of 11 8 mln and brae corp of 15 6 mln reuter 3',\n",
              " \"<sos> the farmers home administration the u s agriculture department's farm lending arm could lose about seven billion dlrs in outstanding principal on its severely delinquent borrowers or about one fourth of its farm loan portfolio the general accounting office gao said in remarks prepared for delivery to the senate agriculture committee brian crowley senior associate director of gao also said that a preliminary analysis of proposed changes in fmha's financial eligibility standards indicated as many as one half of fmha borrowers who received new loans from the agency in 1986 would be ineligible under the proposed system the agency has proposed evaluating applicants' credit using a variety of financial ratios instead of relying solely on cashflow ability senate agriculture committee chairman patrick leahy d vt slammed the proposed eligibility changes telling fmha administrator vance clark at a hearing that they would mark a dramatic shift in the agency's purpose away from being farmers' lender of last resort toward becoming a big city bank but clark defended the new regulations saying the agency had a responsibility to administer its 70 billion dlr loan portfolio in a compassionate yet judicious manner crowley of gao congress' investigative arm said the proposed credit scoring system attempted to ensure that fmha would make loans only to borrowers who had a reasonable change of repaying their debt reuter 3\",\n",
              " '<sos> seton co said its board has received a proposal from chairman and chief executive officer philip d kaltenbacher to acquire seton for 15 75 dlrs per share in cash seton said the acquisition bid is subject to kaltenbacher arranging the necessary financing it said he intends to ask other members of senior management to participate the company said kaltenbacher owns 30 pct of seton stock and other management members another 7 5 pct seton said it has formed an independent board committee to consider the offer and has deferred the annual meeting it had scheduled for march 31 reuter 3']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test1[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1YC89SgfRK3",
        "outputId": "af4f520f-3107-4cf2-e35f-414ecce8be08"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<sos> the great atlantic and pacific tea co said its three year 345 mln dlr capital program will be be substantially increased to accommodate growth and expansion plans for waldbaum inc and shopwell inc over the next two years a and p said the acquisition of shopwell in august 1986 and waldbaum in december helped us achieve better than expected results in the fourth quarter ended february 28 its net income from continuing operations jumped 52 6 pct to 20 7 mln dlrs or 55 cts a share in the latest quarter as sales increased 48 3 pct to 1 58 billion dlrs a and p gave no details on the expanded capital program but it did say it completed the first year of the program during 1986 a and p is 52 4 pct owned by lt tengelmann warenhandelsgesellschaft of west germany reuter 3',\n",
              " \"<sos> philippine sugar production in the 1987 88 crop year ending august has been set at 1 6 mln tonnes up from a provisional 1 3 mln tonnes this year sugar regulatory administration sra chairman arsenio yulo said yulo told reuters a survey during the current milling season which ends next month showed the 1986 87 estimate would almost certainly be met he said at least 1 2 mln tonnes of the 1987 88 crop would be earmarked for domestic consumption yulo said about 130 000 tonnes would be set aside for the u s sugar quota 150 000 tonnes for strategic reserves and 50 000 tonnes would be sold on the world market he said if the government approved a long standing sra recommendation to manufacture ethanol the project would take up another 150 000 tonnes slightly raising the target the government for its own reasons has been delaying approval of the project but we expect it to come through by july yulo said ethanol could make up five pct of gasoline cutting the oil import bill by about 300 mln pesos yulo said three major philippine distilleries were ready to start manufacturing ethanol if the project was approved the ethanol project would result in employment for about 100 000 people sharply reducing those thrown out of work by depressed world sugar prices and a moribund domestic industry production quotas set for the first time in 1987 88 had been submitted to president corazon aquino i think the president would rather wait till the new congress convenes after the may elections he said but there is really no need for such quotas we are right now producing just slightly over our own consumption level the producers have never enjoyed such high prices yulo said adding sugar was currently selling locally for 320 pesos per picul up from 190 pesos last august yulo said prices were driven up because of speculation following the sra's bid to control production we are no longer concerned so much with the world market he said adding producers in the negros region had learned from their mistakes and diversified into corn and prawn farming and cloth production he said diversification into products other than ethanol was also possible within the sugar industry the brazilians long ago learnt their lessons yulo said they have 300 sugar mills compared with our 41 but they relocated many of them and diversified production we want to call this a 'sugarcane industry' instead of the sugar industry he said sugarcane could be fed to pigs and livestock used for thatching roofs or used in room panelling when you cut sugarcane you don't even have to produce sugar he said yulo said the philippines was lobbying for a renewal of the international sugar agreement which expired in 1984 as a major sugar producer we are urging them to write a new agreement which would revive world prices yulo said if there is no agreement world prices will always be depressed particularly because the european community is subsidising its producers and dumping sugar on the markets he said current world prices holding steady at about 7 60 cents per pound were uneconomical for the philippines where production costs ranged from 12 to 14 cents a pound if the price holds steady for a while at 7 60 cents i expect the level to rise to about 11 cents a pound by the end of this year he said yulo said economists forecast a bullish sugar market by 1990 with world consumption outstripping production he said sugar markets were holding up despite encroachments from artificial sweeteners and high fructose corn syrup but we are not happy with the reagan administration he said since 1935 we have been regular suppliers of sugar to the u s in 1982 when they restored the quota system they cut ours in half without any justification manila was keenly watching washington's moves to cut domestic support prices to 12 cents a pound from 18 cents the u s agriculture department last december slashed its 12 month 1987 sugar import quota from the philippines to 143 780 short tons from 231 660 short tons in 1986 yulo said despite next year's increased production target some philippine mills were expected to shut down at least four of the 41 mills were not working during the 1986 87 season he said we expect two or three more to follow suit during the next season reuter 3\",\n",
              " \"<sos> the agriculture department's widening of louisiana gulf differentials will affect county posted prices for number two yellow corn in ten states a usda official said all counties in iowa will be affected as will counties which use the gulf to price corn in illinois indiana tennessee kentucky missouri mississippi arkansas alabama and louisiana said ron burgess deputy director of commodity operations division for the usda usda last night notified the grain industry that effective immediately all gulf differentials used to price interior corn would be widened on a sliding scale basis of four to eight cts depending on what the differential is usda's action was taken to lower excessively high posted county prices for corn caused by high gulf prices we've been following this louisiana gulf situation for a month and we don't think it's going to get back in line in any nearby time burgess said burgess said usda will probably narrow back the gulf differentials when and if gulf prices recede if we're off the mark now because we're too high wouldn't we be as much off the mark if we're too low he said while forecasting more adjustments if gulf prices fall burgess said no other changes in usda's price system are being planned right now we don't tinker we don't make changes lightly and we don't make changes often he said reuter 3\",\n",
              " '<sos> graham mccormick oil and gas partnership said it completed the sale of interests in two major oil and gas fields to lt energy assets international corp for 21 mln dlrs the company said it sold about one half of its 50 pct interest in the oak hill and north rucias fields its two largest producing properties it said it used about 20 mln dlrs of the proceeds to prepay principal on its senior secured notes semi annual principal payments on the remaining 40 mln dlrs of notes have been satisfied until december 1988 as a result it said the company said the note agreements were amended to reflect an easing of some financial covenants and an increase of interest to 13 5 pct from 13 0 pct until december 1990 it said the noteholders exercise price for 1 125 000 warrants was also reduced to 50 cts from 1 50 dlrs the company said energy assets agreed to share the costs of increasing production at the oak hill field reuter 3',\n",
              " '<sos> strong south easterly winds were keeping many vessels trapped in the ice off the finnish and swedish coasts in one of the worst icy periods in the baltic for many years the finnish board of navigation said in finland and sweden up to 50 vessels were reported to be stuck in the ice and even the largest of the assisting icebreakers were having difficulties in breaking through to the stranded ships coastguard officials said however icy conditions in the southern baltic at the soviet oil ports of ventspils and klaipeda had eased they said weather officials in neighbouring sweden said the icy conditions in the baltic were the worst for 30 years with ships fighting a losing battle to keep moving in the coastal stretches of the gulf of bothnia which divides finland and sweden the ice is up to one metre thick with drifts and currents packing it into almost impenetrable walls three metres high swedish coastguard officials said weather forecasts say winds may ease during the weekend but a further drop in temperature could bring shipping to a standstill the officials said reuter 3']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dtmvector = CountVectorizer()\n",
        "tfidf_transformer = TfidfTransformer()"
      ],
      "metadata": {
        "id": "UTP1MdE3ecNU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train1_dtm = dtmvector.fit_transform(x_train1)\n",
        "tfidfv1 = tfidf_transformer.fit_transform(x_train1_dtm)"
      ],
      "metadata": {
        "id": "goU5M_cffwAX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test1_dtm = dtmvector.transform(x_test1)\n",
        "tfidfv_test1 = tfidf_transformer.transform(x_test1_dtm)"
      ],
      "metadata": {
        "id": "WRCrIt08UTG6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb.fit(tfidfv1, y_train1)\n",
        "predicted = nb.predict(tfidfv_test1)\n",
        "print(\"정확도:\", accuracy_score(y_test1, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lT3yKA2g6Afs",
        "outputId": "682c18d5-94fa-4723-b0ce-853f15e6b3cf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 0.5997328584149599\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cb.fit(tfidfv1, y_train1)\n",
        "predicted = cb.predict(tfidfv_test1)\n",
        "print(\"정확도:\", accuracy_score(y_test1, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Df5A2GWg29sg",
        "outputId": "4e84b84c-74cb-40e7-d141-36467f44d89f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 0.7649154051647373\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr.fit(tfidfv1, y_train1)\n",
        "predicted = lr.predict(tfidfv_test1)\n",
        "print(\"정확도:\", accuracy_score(y_test1, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0JqVTuE29ui",
        "outputId": "d9304705-8577-473e-bb5b-2e38943479d3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 0.813446126447017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lsvc.fit(tfidfv1, y_train1)\n",
        "predicted = lsvc.predict(tfidfv_test1)\n",
        "print(\"정확도:\", accuracy_score(y_test1, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PL01y3g29wq",
        "outputId": "a85c579f-42ff-4589-c745-cf96bcc3bb37"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 0.7858414959928762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tree.fit(tfidfv1, y_train1)\n",
        "predicted = tree.predict(tfidfv_test1)\n",
        "print(\"정확도:\", accuracy_score(y_test1, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FO65aloX29yo",
        "outputId": "c39a82cd-2c28-4552-ba73-c5791b3da20d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 0.6211041852181657\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "forest.fit(tfidfv1, y_train1)\n",
        "predicted = forest.predict(tfidfv_test1)\n",
        "print(\"정확도:\", accuracy_score(y_test1, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rS1BBkrK290l",
        "outputId": "56af3aea-8743-4030-911d-cfe93031aa4c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 0.6544968833481746\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grbt.fit(tfidfv1, y_train1)\n",
        "predicted = grbt.predict(tfidfv_test1)\n",
        "print(\"정확도:\", accuracy_score(y_test1, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEtIeb7f292r",
        "outputId": "0a0a7658-d0b4-4168-96c9-2a876f4bfb2b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 0.7702582368655387\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "voting_classifier.fit(tfidfv1, y_train1)\n",
        "predicted = voting_classifier.predict(tfidfv_test1)\n",
        "print(\"정확도:\", accuracy_score(y_test1, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAjbir1A294_",
        "outputId": "b02a1c09-b135-42c7-f02f-3f9412fc7793"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 0.8187889581478184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5,000개 활용"
      ],
      "metadata": {
        "id": "21vme0WpZjU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train2, y_train2), (x_test2, y_test2) = reuters.load_data(num_words=5000, test_split=0.2)"
      ],
      "metadata": {
        "id": "k6VBA8quVO0w"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoded = []\n",
        "for i in range(len(x_train2)):\n",
        "    t = ' '.join([index_to_word[index] for index in x_train2[i]])\n",
        "    decoded.append(t)\n",
        "\n",
        "x_train2 = decoded\n",
        "print(len(x_train2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6e45b77-d404-4dab-bd8d-88976a6cd612",
        "id": "rcTJxN6o_gxa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoded = []\n",
        "for i in range(len(x_test2)):\n",
        "    t = ' '.join([index_to_word[index] for index in x_test2[i]])\n",
        "    decoded.append(t)\n",
        "\n",
        "x_test2 = decoded\n",
        "print(len(x_test2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c15faf2d-824b-4c47-e54e-89987611b6f3",
        "id": "vpPX7fMJ_gxa"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train2_dtm = dtmvector.fit_transform(x_train2)\n",
        "tfidfv2 = tfidf_transformer.fit_transform(x_train2_dtm)"
      ],
      "metadata": {
        "id": "h8Vt42fy_tMn"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test2_dtm = dtmvector.transform(x_test2)\n",
        "tfidfv_test2 = tfidf_transformer.transform(x_test2_dtm)"
      ],
      "metadata": {
        "id": "FVPOS7hN_tMn"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb.fit(tfidfv2, y_train2)\n",
        "predicted = nb.predict(tfidfv_test2)\n",
        "print(\"정확도:\", accuracy_score(y_test2, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99cbe414-a2ed-46f6-c431-75be9f6277e2",
        "id": "--_5z9cq_tMn"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 0.6731967943009796\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cb.fit(tfidfv2, y_train2)\n",
        "predicted = cb.predict(tfidfv_test2)\n",
        "print(\"정확도:\", accuracy_score(y_test2, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35dfdd26-3cb1-47fd-95b1-29ccbfd56053",
        "id": "fJN6uEQ__tMn"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 0.7707034728406055\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr.fit(tfidfv2, y_train2)\n",
        "predicted = lr.predict(tfidfv_test2)\n",
        "print(\"정확도:\", accuracy_score(y_test2, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e36b14e-5b8b-4137-d1b7-0392b1d0de5a",
        "id": "s12j_NmJ_tMn"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 0.8058771148708815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lsvc.fit(tfidfv2, y_train2)\n",
        "predicted = lsvc.predict(tfidfv_test2)\n",
        "print(\"정확도:\", accuracy_score(y_test2, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53f66990-5ac1-4c35-96c4-ada13a978da9",
        "id": "nf63BNiB_tMn"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 0.7671415850400712\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tree.fit(tfidfv2, y_train2)\n",
        "predicted = tree.predict(tfidfv_test2)\n",
        "print(\"정확도:\", accuracy_score(y_test2, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14d7f913-58a5-4343-9495-6c7984525a11",
        "id": "0JpQC5pL_tMo"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 0.6179875333926982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "forest.fit(tfidfv2, y_train2)\n",
        "predicted = forest.predict(tfidfv_test2)\n",
        "print(\"정확도:\", accuracy_score(y_test2, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f92cb7c2-48b9-4a1e-8c0c-45e19a6cfdb7",
        "id": "KuQdHkbG_tMo"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 0.701246660730187\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grbt.fit(tfidfv2, y_train2)\n",
        "predicted = grbt.predict(tfidfv_test2)\n",
        "print(\"정확도:\", accuracy_score(y_test2, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_2uDyAV_tMo",
        "outputId": "10f4217f-aec8-4e64-e6c6-aa2c6a35d36b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 0.767586821015138\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "voting_classifier.fit(tfidfv2, y_train2)\n",
        "predicted = voting_classifier.predict(tfidfv_test2)\n",
        "print(\"정확도:\", accuracy_score(y_test2, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tEZbNnb_tMp",
        "outputId": "d149201a-d7aa-441c-d4c6-725abde9f786"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 0.8161175422974176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 20,000개 활용"
      ],
      "metadata": {
        "id": "9B7VtYhWZl7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train3, y_train3), (x_test3, y_test3) = reuters.load_data(num_words=20000, test_split=0.2)"
      ],
      "metadata": {
        "id": "J0-rbQ2fVQnH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoded = []\n",
        "for i in range(len(x_train3)):\n",
        "    t = ' '.join([index_to_word[index] for index in x_train3[i]])\n",
        "    decoded.append(t)\n",
        "\n",
        "x_train3 = decoded\n",
        "print(len(x_train3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c9498f6-0e01-4fda-b169-514a254bde91",
        "id": "ooF__D09ANmI"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoded = []\n",
        "for i in range(len(x_test3)):\n",
        "    t = ' '.join([index_to_word[index] for index in x_test3[i]])\n",
        "    decoded.append(t)\n",
        "\n",
        "x_test3 = decoded\n",
        "print(len(x_test3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f78cb7a6-c26a-4d9a-aa85-1560c604b4e7",
        "id": "FIunSWUQANmQ"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train3_dtm = dtmvector.fit_transform(x_train3)\n",
        "tfidfv3 = tfidf_transformer.fit_transform(x_train3_dtm)"
      ],
      "metadata": {
        "id": "PptdZr6fANmQ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test3_dtm = dtmvector.transform(x_test3)\n",
        "tfidfv_test3 = tfidf_transformer.transform(x_test3_dtm)"
      ],
      "metadata": {
        "id": "To_iO8QzANmR"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb.fit(tfidfv3, y_train3)\n",
        "predicted = nb.predict(tfidfv_test3)\n",
        "print(\"정확도:\", accuracy_score(y_test3, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c04e675-363f-46db-fade-43f21e1391b3",
        "id": "Q3YMDqgiANmR"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 0.6193232413178985\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cb.fit(tfidfv3, y_train3)\n",
        "predicted = cb.predict(tfidfv_test3)\n",
        "print(\"정확도:\", accuracy_score(y_test3, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c433b50-d10b-4ac8-a01e-fc84c36c1d88",
        "id": "8I_jnsObANmR"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 0.7671415850400712\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr.fit(tfidfv3, y_train3)\n",
        "predicted = lr.predict(tfidfv_test3)\n",
        "print(\"정확도:\", accuracy_score(y_test3, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32505b9e-53d0-44be-8b5c-b70498dd9bd5",
        "id": "PLqdXjXCANmR"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 0.8098842386464826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lsvc.fit(tfidfv3, y_train3)\n",
        "predicted = lsvc.predict(tfidfv_test3)\n",
        "print(\"정확도:\", accuracy_score(y_test3, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e5f0c97-5871-4c60-f966-61b98cabf6d7",
        "id": "HYT6QZtfANmR"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 0.7782724844167409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tree.fit(tfidfv3, y_train3)\n",
        "predicted = tree.predict(tfidfv_test3)\n",
        "print(\"정확도:\", accuracy_score(y_test3, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8d98a46-a15a-4d00-9f81-1d0b0810477b",
        "id": "R35JN6sDANmR"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 0.6211041852181657\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "forest.fit(tfidfv3, y_train3)\n",
        "predicted = forest.predict(tfidfv_test3)\n",
        "print(\"정확도:\", accuracy_score(y_test3, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8ecd242-f46f-429e-9ea5-8ea134491152",
        "id": "ZxqM8yUnANmR"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 0.6714158504007124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grbt.fit(tfidfv3, y_train3)\n",
        "predicted = grbt.predict(tfidfv_test3)\n",
        "print(\"정확도:\", accuracy_score(y_test3, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a0fOK35ANmR",
        "outputId": "ee81593d-6fca-471e-e037-139c79e000ec"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 0.7702582368655387\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "voting_classifier.fit(tfidfv3, y_train3)\n",
        "predicted = voting_classifier.predict(tfidfv_test3)\n",
        "print(\"정확도:\", accuracy_score(y_test3, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ag3eDI9ANmR",
        "outputId": "1ff3221d-4dcc-449f-8116-75ded2de1a44"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 0.8178984861976848\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RNN 학습"
      ],
      "metadata": {
        "id": "kXrHz8o2B-7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_x_train1 = tfidfv1.toarray()\n",
        "rnn_x_test1 = tfidfv_test1.toarray()"
      ],
      "metadata": {
        "id": "8SshyNsjkBgZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 28842\n",
        "word_vector_dim = 200"
      ],
      "metadata": {
        "id": "HwmcxTqbl0-8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmRG-3iD8zbp",
        "outputId": "9bef8824-c2a3-42a0-ecfd-415600dfebba"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "model = keras.Sequential()\n",
        "\n",
        "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
        "model.add(keras.layers.LSTM(32, activation='tanh'))\n",
        "model.add(keras.layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9sV-HtOljK2",
        "outputId": "e64d515d-9ed4-4a77-cc94-de8ca2c6af88"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 200)         5768400   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 32)                29824     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 46)                1518      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,799,742\n",
            "Trainable params: 5,799,742\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "vGnXiWFMB-C7"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "es = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
        "epochs=10  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
        "\n",
        "history = model.fit(rnn_x_train1,\n",
        "                    y_train1,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=128,\n",
        "                    callbacks=[es],\n",
        "                    validation_split=0.2,\n",
        "                    verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "k-O6rKs7YvZ8",
        "outputId": "a80e68ea-8212-4b8d-ffec-9a5b85f47822"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "57/57 [==============================] - 87s 1s/step - loss: 3.0510 - accuracy: 0.3403 - val_loss: 2.4825 - val_accuracy: 0.3450\n",
            "Epoch 2/10\n",
            "57/57 [==============================] - 81s 1s/step - loss: 2.4255 - accuracy: 0.3534 - val_loss: 2.4063 - val_accuracy: 0.3450\n",
            "Epoch 3/10\n",
            "57/57 [==============================] - 81s 1s/step - loss: 2.4072 - accuracy: 0.3534 - val_loss: 2.4069 - val_accuracy: 0.3450\n",
            "Epoch 4/10\n",
            "57/57 [==============================] - 82s 1s/step - loss: 2.4059 - accuracy: 0.3534 - val_loss: 2.4052 - val_accuracy: 0.3450\n",
            "Epoch 5/10\n",
            "29/57 [==============>...............] - ETA: 36s - loss: 2.4217 - accuracy: 0.3556"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-335224b98ad5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                     verbose=1)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import sparse \n",
        "\n",
        "sparse.issparse(rnn_x_test1)\n",
        "\n",
        "results = model.evaluate(rnn_x_test1, y_test1, verbose=2)\n",
        "print(results)"
      ],
      "metadata": {
        "id": "xlrj0Ll8YvfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_x_train2 = tfidfv2.toarray()\n",
        "rnn_x_test2 = tfidfv_test2.toarray()\n",
        "\n",
        "vocab_size = 5000\n",
        "\n",
        "model2 = keras.Sequential()\n",
        "\n",
        "model2.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
        "model2.add(keras.layers.LSTM(32, activation='tanh'))\n",
        "model2.add(keras.layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model2.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history2 = model2.fit(rnn_x_train2,\n",
        "                    y_train2,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=60,\n",
        "                    callbacks=[es],\n",
        "                    validation_split=0.2,\n",
        "                    verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCLbFp8gYvh2",
        "outputId": "35627563-3183-41dc-94eb-aa0fec996ad9"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "120/120 [==============================] - 32s 255ms/step - loss: 2.5427 - accuracy: 0.3406 - val_loss: 2.4095 - val_accuracy: 0.3450\n",
            "Epoch 2/10\n",
            "120/120 [==============================] - 30s 254ms/step - loss: 2.4179 - accuracy: 0.3534 - val_loss: 2.4129 - val_accuracy: 0.3450\n",
            "Epoch 3/10\n",
            "120/120 [==============================] - 30s 253ms/step - loss: 2.4133 - accuracy: 0.3534 - val_loss: 2.4137 - val_accuracy: 0.3450\n",
            "Epoch 4/10\n",
            "120/120 [==============================] - 30s 253ms/step - loss: 2.4131 - accuracy: 0.3534 - val_loss: 2.4090 - val_accuracy: 0.3450\n",
            "Epoch 5/10\n",
            "120/120 [==============================] - 30s 252ms/step - loss: 2.4115 - accuracy: 0.3534 - val_loss: 2.4116 - val_accuracy: 0.3450\n",
            "Epoch 6/10\n",
            "120/120 [==============================] - 30s 253ms/step - loss: 2.4121 - accuracy: 0.3534 - val_loss: 2.4107 - val_accuracy: 0.3450\n",
            "Epoch 7/10\n",
            "120/120 [==============================] - 30s 254ms/step - loss: 2.4130 - accuracy: 0.3534 - val_loss: 2.4099 - val_accuracy: 0.3450\n",
            "Epoch 7: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sparse.issparse(rnn_x_test2)\n",
        "\n",
        "results2 = model2.evaluate(rnn_x_test2, y_test1, verbose=2)\n",
        "print(results2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crjo8_CxYvkN",
        "outputId": "f55f0d20-e069-4c8c-c9ea-9416d14a4138"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71/71 - 5s - loss: 2.4203 - accuracy: 0.3620 - 5s/epoch - 72ms/step\n",
            "[2.420342445373535, 0.36197686195373535]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_x_train3 = tfidfv3.toarray()\n",
        "rnn_x_test3 = tfidfv_test3.toarray()\n",
        "\n",
        "vocab_size = 20000\n",
        "\n",
        "model3 = keras.Sequential()\n",
        "\n",
        "model3.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
        "model3.add(keras.layers.LSTM(32, activation='tanh'))\n",
        "model3.add(keras.layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model3.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history2 = model3.fit(rnn_x_train3,\n",
        "                    y_train3,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=60,\n",
        "                    callbacks=[es],\n",
        "                    validation_split=0.2,\n",
        "                    verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "QeQcHTVSYvnN",
        "outputId": "abea11de-370b-41ac-abfc-e732b2179728"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "120/120 [==============================] - 115s 949ms/step - loss: 2.5143 - accuracy: 0.3442 - val_loss: 2.4121 - val_accuracy: 0.3450\n",
            "Epoch 2/10\n",
            "120/120 [==============================] - 114s 947ms/step - loss: 2.4162 - accuracy: 0.3534 - val_loss: 2.4154 - val_accuracy: 0.3450\n",
            "Epoch 3/10\n",
            "120/120 [==============================] - ETA: 0s - loss: 2.4148 - accuracy: 0.3534"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-89368aa8244c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                     verbose=1)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1429\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m               \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1431\u001b[0;31m               _use_cached_eval_dataset=True)\n\u001b[0m\u001b[1;32m   1432\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1714\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1716\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1717\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sparse.issparse(rnn_x_test3)\n",
        "\n",
        "result3 = model3.evaluate(rnn_x_test3, y_test3, verbose=2)\n",
        "print(result3)"
      ],
      "metadata": {
        "id": "J3V4HZTX-F6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#회고"
      ],
      "metadata": {
        "id": "Hc2IuMqq_Cov"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## F-1 score"
      ],
      "metadata": {
        "id": "S-hZhusF_IOG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "confusion matrix에 대한 개념은 사실 인공지능에서만 나오는 개념도 아닐 뿐더러, 내가 공부했던 정보보안에서도 꽤나 중요하게 다루는 내용이다 보니 어느정도 사전지식을 가지고 있고, 가지고 있던 개념을 토대로 인공지능에서의 관점을 적용해서 이해하고 있다고 생각했고, F1-score도 완벽하지는 않지만 대강은(recall도 precision도 온전히 신뢰할 수 없기 때문에 둘의 조화평균을 계산한다. 정도? 사실 조화평균이라는 표현도 뭔지 모르겠긴 하다.)이해를 하고 있었는데, 각 모델에 적용해보려니 머리가 새하얘졌다. 조금 더 시간을 투자할 수 있었더라면 그래도 적용해볼 수 있었겠지 싶은데 또 이렇게 매번 밀려서 시간투자가 아쉬워진다. 결국 코드가 약하면 결정적으로 결과를 낼 수가 없다. 어쨋든 저쨋든 결국 컴퓨터공학인 이상, 컴퓨터공학적으로 활용하고자 하는 이상 코딩이 정수다."
      ],
      "metadata": {
        "id": "PVmpy08z_Lsp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 결과에 대하여"
      ],
      "metadata": {
        "id": "JFx5BSXsAdyC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "가장 의외이고 이해할 수 없었던 점은 가장 적은 단어를 활용한 사례가 오히려 높은 성능을 발휘했다는 것이다. 내가 잘못한 건지 이게 합리적인 결과인지를 모르겠어서 걱정스럽다. 심지어 모든 단어를 활용한 경우가 성능이 몹시 낮다. 하긴 글의 종류를 여러 개 주어주고 맞추는 문제라면 사실 인간의 입장에서는 단어가 5,000개까지도 필요가 없지 싶다. 항상 그래왔듯이 하고자 하는 태스크에 맞게 데이터의 갯수던 모델의 깊이던 설정해야 좋은 성능을 보여주는 것 같다. 문제는 아직 태스크에 따른 적절한 수준을 판단할 수 없다는 점이지만..."
      ],
      "metadata": {
        "id": "exGMog4CAuqY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## fit_transform & transform"
      ],
      "metadata": {
        "id": "gKt3DB-wE4Mf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "슥 보고 같은 함수라고 생각하고 긁어서 쓰다가 에러를 만나 얼떨결에 공부하게 되었다.\n",
        "완벽하게 이해한 것은 아니지만 결론만 얘기하자면 fit_transform()은 train data에만 사용한다. mean과 varience를 학습하기 때문인데, test data에 fit_transform을 사용할 경우 새로운 mean과 varience를 학습하게 되어 학습의 성능을 점검하게 되는 것이 아닌 새로운 학습을 하게 된다는 것이다."
      ],
      "metadata": {
        "id": "B9rdPaneGYVs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 딥러닝 모델"
      ],
      "metadata": {
        "id": "V6nkrIJsrTzD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "딥러닝 모델과의 비교까지는 해보려 했는데 역시 순탄치 않았다. 몇 푼 안되지만 돈주고 등록한 GPU는 LSTM의 유닛을 늘리거나 다층 LSTM으로 쌓는 순간 터져서 멈추기 일쑤였고, 그럴 때마다 세션을 통째로 날려버려서 처음부터 다시 돌려야 했다. 뒤에 fully connected dense 레이어를 쌓아보기도 하고, scaler 기법? 이라는 알지 못했던 코드를 넣어보기도 했다. 아무튼 성능이 비교 가능한 수준으로 올라가지가 않는다. 이 태스크를 LSTM으로 보여줄만한 성능을 낼 수가 있는게 맞긴한걸까? 학습을 성공시킨 코드를 정말 보고싶다."
      ],
      "metadata": {
        "id": "lZdCwrzIs7p_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# REF\n",
        "* fit_transform & transform<br>\n",
        "https://deepinsight.tistory.com/165\n",
        "<br>\n",
        "<br>\n",
        "* LSTM<br>\n",
        "https://ebbnflow.tistory.com/135<br>\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM<br>\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense<br>\n",
        "https://blog.naver.com/PostView.nhn?blogId=htk1019&logNo=221255254613<br>\n",
        "https://wdprogrammer.tistory.com/23"
      ],
      "metadata": {
        "id": "z2jvOvd-uQno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NOnIcHyWuSKC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}